{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de las librerías necesarias\n",
    "Se importan las librerías necesarias para la ejecución del algoritmo.\n",
    "\n",
    "Las librerías deben estar previamente instaladas en Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dateutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos\n",
    "Función para leer los archivos de datos necesarios para ejecutar el algoritmo y preparar los datos para su ejecución, es decir, construir los campos adicionales requeridos.\n",
    "\n",
    "El archivo debe contener los siguientes campos en ese orden:\n",
    "* ID_Transformador\n",
    "* Fecha\n",
    "* Voltaje_F1_V\n",
    "* Voltaje_F2_V\n",
    "* Voltaje_F3_V\n",
    "* Corriente_F1_A\n",
    "* Corriente_F2_A\n",
    "* Corriente_F3_A\n",
    "* Factor_Potencia\n",
    "* Energia_Activa_kWh\t\n",
    "* Energia_Reactiva_kVAR\n",
    "* Potencia_Activa_kW\n",
    "* Potencia_Reactiva_kVAR\n",
    "* Potencia_Aparente_kVA\n",
    "\n",
    "El separador de decimales debe ser punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    global data\n",
    "    \n",
    "    data = pd.read_csv(\"datos.csv\", sep=',', decimal='.')\n",
    "    \n",
    "    # eliminar las comas\n",
    "    data.columns = [col.replace(',','') for col in data.columns]\n",
    "    \n",
    "    # construir columnas necesarias para el análisis\n",
    "    data['Fecha'] = data['Fecha'].apply(dateutil.parser.parse, dayfirst=True)\n",
    "    data['ano'] = pd.DatetimeIndex(data['Fecha']).year\n",
    "    data['mes'] = pd.DatetimeIndex(data['Fecha']).month\n",
    "    data['dia'] = pd.DatetimeIndex(data['Fecha']).day\n",
    "    data['hora'] = pd.DatetimeIndex(data['Fecha']).hour\n",
    "    data['minuto'] = pd.DatetimeIndex(data['Fecha']).minute\n",
    "    data = data.sort_values(['ID_Transformador', 'Fecha'], ascending=[True, True])\n",
    "    data['carga'] = data['Energia_Activa_kWh'] - data['Energia_Activa_kWh'].shift(1) \n",
    "    data.loc[(data.carga < 0), 'carga'] = np.nan\n",
    "    data.loc[(data.hora != data.hora.shift(1)) & (data.hora - 1 != data.hora.shift(1)), 'carga'] = np.nan\n",
    "    data.loc[(data.dia != data.dia.shift(1)) & (data.dia - 1 != data.dia.shift(1)), 'carga'] = np.nan\n",
    "    \n",
    "    # remover outliers\n",
    "    # Los outliers se presentan por inconsistencias en la informacion.\n",
    "    # Outlier: dato que esta a mas de 2.5 desviaciones estandar de la media.\n",
    "    grupos = data.groupby(['ID_Transformador'])\n",
    "    prov = pd.DataFrame(grupos['carga'].mean())\n",
    "    prov['LS'] = grupos['carga'].mean() + grupos['carga'].std() * 2.5\n",
    "    prov['LI'] = grupos['carga'].mean() - grupos['carga'].std() * 2.5\n",
    "    prov['id_t'] = prov.index\n",
    "    data = data.rename(columns={'ID_Transformador': 'id_t'})\n",
    "    data = data.merge(prov[['LS','LI','id_t']], on = 'id_t',how='right')\n",
    "    data.loc[(data.carga >= data.LS) | (data.carga <= data.LI), 'carga'] = np.nan    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular carga máxima y carga promedio por nodo\n",
    "Función para calcular la carga maxima y la carga promedio de cada nodo por dia\n",
    "* carga máxima por día: maxima de las cargas consolidadas por hora.\n",
    "* carga promedio por día: promedio de las cargas consolidadas por hora.\n",
    "* carga máxima por modo: promedio de las cargas maximas por dia.\n",
    "* carga promedio por nodo: promedio de las cargas promedio por dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmaxpromnodo():\n",
    "\n",
    "    global c_max_prom_nodo\n",
    "    \n",
    "    grupos1 = data.groupby(['id_t','ano','mes','dia','hora'])\n",
    "    prov1 = pd.DataFrame(grupos1['carga'].sum())\n",
    "\n",
    "    # cálculos por nodo, por día\n",
    "    grupos2 = prov1.groupby(['id_t','ano','mes','dia'])\n",
    "    c_max_prom_dia = pd.DataFrame(grupos2['carga'].max())\n",
    "    c_max_prom_dia['cmax'] = grupos2['carga'].max()\n",
    "    c_max_prom_dia['cpro'] = grupos2['carga'].mean()\n",
    "    \n",
    "    # consolidados por nodo\n",
    "    grupos = c_max_prom_dia.groupby(['id_t','ano'])\n",
    "    c_max_prom_nodo = pd.DataFrame(grupos['cmax'].max())\n",
    "    c_max_prom_nodo['cmax'] = grupos['cmax'].mean()\n",
    "    c_max_prom_nodo['prom'] = grupos['cpro'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular demanda promedio por nodo\n",
    "Función para calcular la demanda promedio de cada nodo, como el promedio de las demandas por día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddapromnodo():\n",
    "\n",
    "    global d_prom_nodo\n",
    "    \n",
    "    grupos = data.groupby(['id_t','ano','mes','dia'])\n",
    "    prov = pd.DataFrame(grupos['carga'].sum())\n",
    "    prov['horas_med'] = ((grupos['Fecha'].max() - grupos['Fecha'].min()).dt.total_seconds())/(60*60)\n",
    "    prov['dda_med'] = grupos['Energia_Activa_kWh'].max() - grupos['Energia_Activa_kWh'].min()\n",
    "    prov['dda_dia'] = prov['dda_med'] / prov['horas_med'] * 24\n",
    "    \n",
    "    grupos1 = prov.groupby(['id_t','ano'])\n",
    "    d_prom_nodo = pd.DataFrame(grupos1['dda_dia'].mean())\n",
    "    d_prom_nodo.index.names = ['id_tf','ano']\n",
    "    d_prom_nodo['id_t'] = d_prom_nodo.index.get_level_values('id_tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run\n",
    "Función para consolidar la informacion de carga promedio, carga maxima y demanda por nodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    cmaxpromnodo()\n",
    "    ddapromnodo()\n",
    "    cyd_pornodo = c_max_prom_nodo.merge(d_prom_nodo[['dda_dia','id_t']], on = 'id_t',how='right')\n",
    "    \n",
    "    # reporte en csv\n",
    "    cyd_pornodo.to_csv('ResData/cyd_pornodo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutar\n",
    "Celda desde donde se ejecutan las dos rutinas esenciales:\n",
    "\n",
    "* load_data(): carga de información\n",
    "* run (): ejecución del algoritmo\n",
    "\n",
    "En esta celda se especifican también los directorios de trabajo y la demanda con la cual se desea ejecutar la simulación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data()\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
